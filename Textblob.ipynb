{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a natural language processing library (NLP)\n",
    "\n",
    "TextBlob : TextBlob is a python library and offers a simple API to access its methods and perform basic NLP tasks. \n",
    "    \n",
    "TextBlob can perform below things :\n",
    "1.Tokenization\n",
    "2.Noun phrase extraction\n",
    "3.POS-Tagging\n",
    "4.N-grams\n",
    "5.Sentiment Analysis\n",
    "\n",
    "Other things we can do with TextBlob\n",
    "1.Spelling correction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in c:\\users\\prati\\anaconda3\\lib\\site-packages (0.15.3)\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\users\\prati\\anaconda3\\lib\\site-packages (from textblob) (3.4.5)\n",
      "Requirement already satisfied: six in c:\\users\\prati\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (1.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love data science and machine learning. AI is the new future. I want to be a Data Scientist\n",
      "[Sentence(\"I love data science and machine learning.\"), Sentence(\"AI is the new future.\"), Sentence(\"I want to be a Data Scientist\")]\n",
      "['I', 'love', 'data', 'science', 'and', 'machine', 'learning', 'AI', 'is', 'the', 'new', 'future', 'I', 'want', 'to', 'be', 'a', 'Data', 'Scientist']\n"
     ]
    }
   ],
   "source": [
    "#Tokenization\n",
    "import nltk\n",
    "#nltk.download('punkt')\n",
    "\n",
    "from textblob import TextBlob\n",
    "\n",
    "blob = TextBlob(\"I love data science and machine learning. AI is the new future. I want to be a Data Scientist\")\n",
    "print(blob)\n",
    "print(blob.sentences)\n",
    "print(blob.words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=blob.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['I', 'love', 'data', 'science', 'and', 'machine', 'learning', 'AI', 'is', 'the', 'new', 'future', 'I', 'want', 'to', 'be', 'a', 'Data', 'Scientist'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\n",
      "love\n",
      "data\n",
      "science\n",
      "and\n",
      "machine\n",
      "learning\n",
      "AI\n",
      "is\n",
      "the\n",
      "new\n",
      "future\n",
      "I\n",
      "want\n",
      "to\n",
      "be\n",
      "a\n",
      "Data\n",
      "Scientist\n"
     ]
    }
   ],
   "source": [
    "for i in data :\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data science\n",
      "machine learning\n",
      "ai\n",
      "new future\n",
      "data scientist\n"
     ]
    }
   ],
   "source": [
    "#Noun Phrase Extraction\n",
    "for np in blob.noun_phrases:\n",
    " print (np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np=blob.noun_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['data science', 'machine learning', 'ai', 'new future', 'data scientist'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data science\n",
      "machine learning\n",
      "ai\n",
      "new future\n",
      "data scientist\n"
     ]
    }
   ],
   "source": [
    "for i in np :\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part-of-speech Tagging\n",
    "Part-of-speech tagging or grammatical tagging is a method to mark words present in a text on the basis of its definition and context. In simple words, it tells whether a word is a noun, or an adjective, or a verb, etc. This is just a complete version of noun phrase extraction, where we want to find all the the parts of speech in a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "v=blob.tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'PRP'),\n",
       " ('love', 'VBP'),\n",
       " ('data', 'NNS'),\n",
       " ('science', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('machine', 'NN'),\n",
       " ('learning', 'NN'),\n",
       " ('AI', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('the', 'DT'),\n",
       " ('new', 'JJ'),\n",
       " ('future', 'NN'),\n",
       " ('I', 'PRP'),\n",
       " ('want', 'VBP'),\n",
       " ('to', 'TO'),\n",
       " ('be', 'VB'),\n",
       " ('a', 'DT'),\n",
       " ('Data', 'NNP'),\n",
       " ('Scientist', 'NN')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I PRP\n",
      "love VBP\n",
      "data NNS\n",
      "science NN\n",
      "and CC\n",
      "machine NN\n",
      "learning NN\n",
      "AI NNP\n",
      "is VBZ\n",
      "the DT\n",
      "new JJ\n",
      "future NN\n",
      "I PRP\n",
      "want VBP\n",
      "to TO\n",
      "be VB\n",
      "a DT\n",
      "Data NNP\n",
      "Scientist NN\n"
     ]
    }
   ],
   "source": [
    "#Part-of-speech Tagging\n",
    "\n",
    "for words, tag in blob.tags:\n",
    "    print (words, tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'love', 'data', 'science']\n",
      "['love', 'data', 'science', 'and']\n",
      "['data', 'science', 'and', 'machine']\n",
      "['science', 'and', 'machine', 'learning']\n",
      "['and', 'machine', 'learning', 'AI']\n",
      "['machine', 'learning', 'AI', 'is']\n",
      "['learning', 'AI', 'is', 'the']\n",
      "['AI', 'is', 'the', 'new']\n",
      "['is', 'the', 'new', 'future']\n",
      "['the', 'new', 'future', 'I']\n",
      "['new', 'future', 'I', 'want']\n",
      "['future', 'I', 'want', 'to']\n",
      "['I', 'want', 'to', 'be']\n",
      "['want', 'to', 'be', 'a']\n",
      "['to', 'be', 'a', 'Data']\n",
      "['be', 'a', 'Data', 'Scientist']\n"
     ]
    }
   ],
   "source": [
    "#N-grams\n",
    "for ngram in blob.ngrams(4):\n",
    "    print (ngram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Sentiment Analysis\n",
    "\n",
    "Polarity is a float value within the range [-1.0 to 1.0] where 0 indicates neutral, +1 indicates a very positive sentiment and -1 represents a very negative sentiment. \n",
    "\n",
    "Subjectivity is a float value within the range [0.0 to 1.0] where 0.0 is very objective and 1.0 is very subjective. Subjective sentence expresses some personal feelings, views, beliefs, opinions, allegations, desires, beliefs, suspicions, and speculations where as Objective sentences are factual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1= TextBlob (\"I love Sunday\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(polarity=0.5, subjectivity=0.6)\n"
     ]
    }
   ],
   "source": [
    "print(format(t1.sentiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2= TextBlob (\"I hate Monday\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(polarity=-0.8, subjectivity=0.9)\n"
     ]
    }
   ],
   "source": [
    "print(format(t2.sentiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spelling Correction\n",
    "blob = TextBlob('YouTube is a gret platfrm to learn data scence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"YouTube is a great platform to learn data science\")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.correct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fuzzywuzzy in c:\\users\\prati\\anaconda3\\lib\\site-packages (0.18.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install fuzzywuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prati\\Anaconda3\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "from fuzzywuzzy import fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuzz.ratio(\"zxt\",\"abc@gmail.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
